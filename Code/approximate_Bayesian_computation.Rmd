---
title: "Approximate Bayesian Computation"
author: "Grace Smith-Vidaurre"
date: "September 23, 2020"
output: html_document
---

```{r setup, eval = TRUE, echo = FALSE}

knitr::opts_knit$set(root.dir = "/home/owner/Desktop/GitHub_repos/origins-selection")

```

Purpose: Approximate Bayesian Computation analyses using the multidimensional site frequency spectrum (mSFS), the delimitR package developed by Megan Smith, and fastsimcaol2 for simulating the mSFS under different demographic scenarios. Installed delimitR version 2.0.2 from GitHub: https://github.com/meganlsmith. Had to install dependencies abcrf, sqldf and reticulate. Also installed the package radiator to convert between genind object and VCF format, needed to use Python code in another GitHub repo to get observed SFS data.

Here, 6 models will be run per invasive population with sufficient samples: Uruguay (URY) origin, Northern Argentina (NAR) origin, admixed origin, and these same 3 models but with a longer bottleneck time that goes to the present. 

```{r echo = TRUE, eval = TRUE, message = FALSE}

rm(list = ls())

# library(devtools)
# install_github("thierrygosselin/radiator")

X <- c("tidyverse", "pbapply", "data.table", "adegenet", "openxlsx", "abcrf", "delimitR", "radiator")
invisible(lapply(X, library, character.only = TRUE))

# Path to the metadata spreadsheet
xls_path <- "/home/owner/Desktop/MANUSCRIPTS/Origins_Selection/DATA/Metadata_Barcodes"

# Path to Stacks output, including the HWE filtered SNPs in Structure format 
res_path <- "/media/owner/MYIOPSITTA/R/Origins_Selection/stacks"

# Path where ABC files will be written
out_path <- "/media/owner/MYIOPSITTA/R/Origins_Selection/ABC"
 
# Path where population maps written
map_path <- "/media/owner/MYIOPSITTA/R/Origins_Selection/info"

gpath <- "/home/owner/Desktop/MANUSCRIPTS/Origins_Selection/GRAPHICS"
seed <- 401

```

Read in metadata.
```{r echo = TRUE, eval = TRUE}

meta_dats <- read.xlsx(file.path(xls_path, "Mymon_RADlibraries_2015_2019_CombinedMetadata.xlsx"))
glimpse(meta_dats)

```

Read in the dataset of pre-processed neutral SNPs from the merged dataset. The number of individuals and loci is documented in BayeScan_post-processing.Rmd.
```{r echo = TRUE, eval = TRUE}

file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs.str"

neutral_snps <- read.structure(file.path(file.path(res_path, "merged"), file_nm), n.ind = 173, n.loc = 320, col.lab = 1, col.pop = 2, row.marknames = 1, onerowperind = FALSE, ask = FALSE, NA.char = "-9")
str(neutral_snps)

str(neutral_snps@tab)

```

# Making population maps to get VCF files via Stacks for ABC modelling

How many invasive populations have sufficient samples (> 4 individuals) for ABC modelling?
```{r echo = TRUE, eval = TRUE}

# Get sampling sites
sites <- sapply(1:nrow(neutral_snps@tab), function(i){
  meta_dats$Site_Code[grep(paste("^", dimnames(neutral_snps@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(sites)

# Get sampling regions
regions <- sapply(1:nrow(neutral_snps@tab), function(i){
  meta_dats$Region[grep(paste("^", dimnames(neutral_snps@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(regions)

# Get native or invasive range
ranges <- sapply(1:nrow(neutral_snps@tab), function(i){
  meta_dats$Population[grep(paste("^", dimnames(neutral_snps@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(ranges)

samps_df <- data.frame(indiv = dimnames(neutral_snps@tab)[[1]]) %>%
  dplyr::mutate(
    site = sites,
    region = regions,
    range = ranges
  )
glimpse(samps_df)

# Only SEVI has too few samples (1 bird) for modelling
samps_df %>%
  filter(range == "Invasive") %>%
  group_by(site) %>%
  dplyr::summarise(
    n_indivs = n_distinct(indiv) 
  )

# Remove the SEVI individual, and all SAR individuals
samps_df <- samps_df %>%
  filter(site != "SEVI") %>%
  filter(region != "Southern Argentina") %>%
  droplevels()
glimpse(samps_df)

samps_df %>%
  pull(region) %>%
  unique()

# Add a column indicating population label for ABC modelling
samps_ABC_df <- samps_df %>%
  dplyr::mutate(
    ABC_pop = region,
    ABC_pop = recode(ABC_pop,
      `Southwestern Uruguay` = "pop1",
      `South Central Uruguay` = "pop1",
      `Spain` = "pop2",
      `Northern United States` = "pop2",
      `Southern United States` = "pop2",
      `Northern Argentina` = "pop3"
    )
  )
glimpse(samps_ABC_df)

# Randomly select 10 birds per region of URY to make models less unbalaned (oterwise 14 NAR and 45 URY individuals per model)
samps_ABC_df <- samps_ABC_df %>%
  filter(grepl("Uruguay", region)) %>%
  group_by(region) %>%
  nest() %>%
  ungroup() %>%
  dplyr::mutate(
    rsamp = map2(data, 10, sample_n, replace = FALSE)
  ) %>%
  select(-data) %>%
  unnest(rsamp) %>%
  bind_rows(
    samps_ABC_df %>%
    filter(!grepl("Uruguay", region))
  )

# glimpse(samps_ABC_df)
# View(samps_ABC_df)

```

Make a population map per each of the remaining 9 invasive populations. This map will have URY, NAR and INV birds (per each invasive population), but not SAR (to avoid making models too complex). The population map should encode URY individuals as pop1, INV individuals as pop2, and NAR individuals as pop3.
```{r echo = TRUE, eval = TRUE}

# Iterate over invasive range sampling sites
sites <- samps_ABC_df %>%
  filter(range == "Invasive") %>%
  pull(site) %>%
  unique() %>%
  as.character()
sites 
length(sites)  

# x <- 1
# i <- 1
invisible(pblapply(1:length(sites), function(x){
  
  # Initialize file name
  file_nm <- file.path(map_path, paste("popmap_mergedSNPs_ABCmodelling_", sites[x], ".txt", sep = ""))

  # Remove previous versions
  file.remove(file.path(map_path, paste("popmap_mergedSNPs_ABCmodelling_", sites[x], ".txt", sep = "")))
  
  # Get individuals for the given iteration
  tmp_df <- samps_ABC_df %>%
    filter(range == "Native" | site == sites[x]) %>%
    droplevels()
  
  # Order by ABC population
  tmp_df <- tmp_df %>%
    arrange(-desc(ABC_pop))
  # glimpse(tmp_df)
  # View(tmp_df)
    
  # Get individuals
  indivs <- tmp_df %>%
    pull(indiv) %>%
    as.character()
  
  # Get ABC populations
  ABC_pops <- tmp_df %>%
    pull(ABC_pop) %>%
    as.character()
  
  # Iterate over individuals to write out lines to this file
  pblapply(1:length(indivs), function(i){
  
    # Initialize the ABC population for the given sample
    reg <- ABC_pops[i]
  
    # Initialize the suffix to go after the sample name
    # Use ".1" for the PE reads here, since I used only the forward reads when merging SE and PE libraries
    suff <- ifelse(grepl("^SE_", indivs[i]), ".fil.sorted", ".1.sorted")
  
    # If not on the last individual, write out a new line symbol to start the next sample on a new line
    # No suffix after the sample name, to allow Stacks to recognize the paired-end file suffix after kmer_filter (.1.1.fil.fq and .2.2.fil.fq)
    if(i != length(indivs)){
      tmp_line <- paste(paste(paste(indivs[i], suff, sep = ""), reg, sep = "\t"), "\n", sep = "")
    } else {
      tmp_line <- paste(paste(indivs[i], suff, sep = ""), reg, sep = "\t")
    }
  
    if(i == 1){
      cat(tmp_line, file = file_nm)
    } else {
      cat(tmp_line, file = file_nm, append = TRUE)
    }
  
  })
 
}))

# Opened these files in Vim to doublecheck structure, looks good

# BARC: 39 individuals total
# CNCT: 61 individuals total
# FLOR: 63 individuals total
# GRCA: 40 individuals total
# ILLI: 42 individuals total
# MADR: 39 individuals total
# MALL: 41 individuals total
# WASH: 38 individuals total
# ZARA: 38 individuals total

```

The whitelist of the 320 neutral loci made in "FST_calculations.Rmd" will be used to retain these neutral loci for each VCF file. 

Once these were made, I uploaded to the info folder on Discovery, and made a new script to run Stacks::populations with the whitelist of 320 neutral loci to get VCF files so as to calculate the observed mSFS with easySFS.py.

### OLDER CODE

Make a new data frame with metdata for these samples. Using DAPC output here. 
```{r echo = TRUE, eval = TRUE}

# Get sample locations from metadata in the same order of samples in the genind object
grp1 <- sapply(1:nrow(neutral_snps@tab), function(i){
  meta_dats$Site_Code[grep(paste("^", dimnames(neutral_snps@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(grp1)
length(grp1)

# Population identifiers by country, then sampling site
# Same order as in Structure file (taken from BayeScan_post-processing.Rmd)
all_sites <- c("CHAC", "ELGE", "EMBR", "SEMI-3", "SOLE", "1135", "1145", "BAGU", "BCAR", "PEIX", "ALGA", "BAIR", "LURO", "BAZO", "ERIO", "BARC", "MADR", "MALL", "SEVI", "ZARA", "GRCA", "FLOR", "ILLI", "WASH", "CNCT")

# Change levels to be in order of country and sampling sites above
grp1 <- factor(grp1, levels = all_sites)

# If all PCs used, then no points will show up, just labels for sampling sites
# Here selected the number of PCs that contained 60% of variation, and 2 discriminant functions
dapc1 <- dapc(neutral_snps, pop = grp1, n.da = 2, pca.select = "percVar", perc.pca = 60)

unique(meta_dats$Region)

all_regs <- c("Southwestern Uruguay", "South Central Uruguay", "Northern Argentina", "Southern Argentina", "Spain", "Southern U.S.", "Northern U.S.")

region <- meta_dats %>%
  filter(Sample_Name %in% dimnames(dapc1$ind.coord)[[1]]) %>%
  pull(Region)

dapc_df <- data.frame(
  X = dapc1$ind.coord[, 1],
  Y = dapc1$ind.coord[, 2]
  ) %>%
  dplyr::mutate(
    type = rep("Neutral merged SNPs", nrow(dapc1$ind.coord)),
    indiv = dimnames(dapc1$ind.coord)[[1]],
    region = gsub("United States", "U.S.", region),
    region = factor(region, levels = all_regs),
    site = grp1
  )

glimpse(dapc_df)

```

Make new files called "ABC_populations_modelX.txt" that contain strata or populations for each ABC model (necessary for writing out VCF file and getting observed SFS per ABC model).

Initialize all unique demes to be used across models: URY-NAR, URY, NAR, SAR, SPA, USA, CNCT. 
```{r echo = TRUE, eval = TRUE}

# URY-NAR, 59 individuals
ury_nar <- dapc_df %>%
  filter(grepl("Uruguay|Northern Argentina", region)) %>%
  pull(indiv) 

head(ury_nar)
length(ury_nar)

# URY, 45 individuals
ury <- dapc_df %>%
  filter(grepl("Uruguay", region)) %>%
  pull(indiv) 

head(ury)
length(ury)
  
# NAR, 14 individuals
nar <- dapc_df %>%
  filter(grepl("Northern Argentina", region)) %>%
  pull(indiv) 

head(nar)
length(nar)  

# SAR, 18 individuals
sar <- dapc_df %>%
  filter(grepl("Southern Argentina", region)) %>%
  pull(indiv) 

head(sar)
length(sar)

```

# Native range ABC modelling

Models 1 and 3: 2 demes. Make a tab delimited file with column headers INDIVIDUALS and STRATA for radiator::genomic_converter. Make a tab delimited file without headers for the easy_SFS.py script.
```{r echo = TRUE, eval = FALSE}

# Make a temporary data frame for Model 1
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury, nar, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY-NAR",
      `South Central Uruguay` = "URY-NAR",
      `Northern Argentina` = "URY-NAR",
      `Southern Argentina` = "SAR"
    )
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY-NAR` = "pop1",
      `SAR` = "pop2"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df) 

# Text file for radiator
file_nm <- "radiator_strata_models_1and3.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_models_1and3.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both files in Vim, both look good

```

Models 2 and 4: 3 demes.
```{r echo = TRUE, eval = FALSE}

# Make a temporary data frame for Model 2
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury, nar, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY",
      `South Central Uruguay` = "URY",
      `Northern Argentina` = "NAR",
      `Southern Argentina` = "SAR"
    )
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY` = "pop1",
      `NAR` = "pop2",
      `SAR` = "pop3"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df)

# Text file for radiator
file_nm <- "radiator_strata_models_2and4.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_models_2and4.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both files in Vim, both look good

```

Used radiator to convert from genind format to VCF per model, write out VCF files per models with the same demes. radiator path setting is bad: assumes a path inside thre current working directory, so I have to set my directory for it to work
```{r echo = TRUE, eval = FALSE}

setwd(out_path)

sfiles <- list.files(out_path, pattern = "^radiator_", full.names = TRUE)
sfiles

runs <- seq(1, 2, 1)
suffs <- c("models_1and3", "models_2and4")

class(neutral_snps)
detect_genomic_format(neutral_snps)

# i <- 1
invisible(pblapply(1:length(runs), function(i){
  genomic_converter(data = neutral_snps, output = "vcf", filename = paste("ABC_", suffs[i], sep = ""), strata = sfiles[i], vcf.metadata = FALSE, vcf.stats = FALSE)
  # any(is.na(tmp$tidy.data$MARKERS))
  # any(is.na(tmp$tidy.data$POP_ID))
  # any(is.na(tmp$tidy.data$INDIVIDUALS))
  # any(is.na(tmp$tidy.data$GT))
  # any(is.na(tmp$tidy.data$REF))
  # any(is.na(tmp$tidy.data$ALT))
  # any(is.na(tmp$tidy.data$GT_VCF))
  # any(is.na(tmp$tidy.data$GT_BIN)) # This column has NAs....
  
  # Works just fine, underscores are automatically changed to dashes
  # read_strata(sfiles[i])
  
}))

# For every run I get an error that a separator is not valid, despite changing all "_" to "-" but the strata file is read in just fine and the package detects the genind class

# I also get an error about NAs created which I think is related to the NA in the POS field in the resulting VCF file, but everything else looks good:
# Warning messages:
# 1: Problem with `mutate()` input `LOCUS`.
# ℹ NAs introduced by coercion
# ℹ Input `LOCUS` is `stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_")`. 
# 2: In stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_") :
#   NAs introduced by coercion

# Looks like this just an error from reading in data with tifyr?
# Resulting VCF file looks different compared to Stacks VCF file, has just genotypes

```

I moved the resulting VCF files out of the ./radiator_genomic_converter* directories and into /media/owner/MYIOPSITTA/R/Origins_Selection/ABC/.

Followed instructions for calculating observed SFSs in this GitHub repo: https://github.com/isaacovercast/easySFS. I used Pycharm to use a virtual environment with Python3.

After using easySFS.py to downproject and get mSFS, I started running simulations for these 4 models on Discovery with fastsimcoal2.6. See the delimitR tutorial for more details.

 



########## OLDER, Update as needed

Initialize all unique demes to be used across models: URY-NAR, URY, NAR, SAR, SPA, USA, CNCT. 
```{r echo = TRUE, eval = TRUE}

# URY-NAR, 59 individuals
ury_nar <- dapc_df %>%
  filter(grepl("Uruguay|Northern Argentina", region)) %>%
  pull(indiv) 

head(ury_nar)
length(ury_nar)

# URY, 45 individuals
ury <- dapc_df %>%
  filter(grepl("Uruguay", region)) %>%
  pull(indiv) 

head(ury)
length(ury)
  
# NAR, 14 individuals
nar <- dapc_df %>%
  filter(grepl("Northern Argentina", region)) %>%
  pull(indiv) 

head(nar)
length(nar)  

# SAR, 18 individuals
sar <- dapc_df %>%
  filter(grepl("Southern Argentina", region)) %>%
  pull(indiv) 

head(sar)
length(sar)

# SPA, 28 individuals
spa <- dapc_df %>%
  filter(grepl("Spain", region)) %>%
  pull(indiv) 

head(spa)
length(spa)  

# USA (no CNCT), 41 individuals
usa <- dapc_df %>%
  filter(grepl("U.S.", region) & !grepl("CNCT", site)) %>%
  pull(indiv) 

head(usa)
length(usa)

# CNCT, 27 individuals
cnct <- dapc_df %>%
  filter(grepl("CNCT", site)) %>%
  pull(indiv) 

head(cnct)
length(cnct)

```

Model 1: 5 demes. Make a tab delimited file with column headers INDIVIDUALS and STRATA for radiator::genomic_converter. Make a tab delimited file without headers for the easy_SFS.py script.
```{r echo = TRUE, eval = FALSE}

# Make a temporary data frame for Model 1
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury_nar, spa, cnct, usa, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY-NAR",
      `South Central Uruguay` = "URY-NAR",
      `Northern Argentina` = "URY-NAR",
      `Spain` = "SPA",
      `Northern U.S.` = "USA",
      `Southern U.S.` = "USA",
      `Southern Argentina` = "SAR"
    ),
    region = ifelse(site == "CNCT", "CNCT", region)
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY-NAR` = "pop1",
      `SPA` = "pop2",
      `CNCT` = "pop3",
      `USA` = "pop4",
      `SAR` = "pop5"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df) 

# Text file for radiator
file_nm <- "radiator_strata_model_1.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_model_1.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both file in Vim, both look good

```

Model 2: 6 demes.
```{r echo = TRUE, eval = FALSE}

# Make a temporary data frame for Model 2
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury_nar, spa, cnct, usa, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY",
      `South Central Uruguay` = "URY",
      `Northern Argentina` = "NAR",
      `Spain` = "SPA",
      `Northern U.S.` = "USA",
      `Southern U.S.` = "USA",
      `Southern Argentina` = "SAR"
    ),
    region = ifelse(site == "CNCT", "CNCT", region)
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY` = "pop1",
      `SPA` = "pop2",
      `CNCT` = "pop3",
      `USA` = "pop4",
      `NAR` = "pop5",
      `SAR` = "pop6"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df)

# Text file for radiator
file_nm <- "radiator_strata_model_2.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_model_2.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both file in Vim, both look good

```

For models 3 and 4, I just copied the text files made for model 2, as these had the same 6 demes. 

Use radiator to convert from genind format to VCF per model, write out VCF files per model. VCF files are the same for models 2 - 4. radiator path setting is bad: assumes a path inside thre current working directory, so I have to set my directory for it to work
```{r echo = TRUE, eval = FALSE}

setwd(out_path)

sfiles <- list.files(out_path, pattern = "^radiator_", full.names = TRUE)
sfiles

models <- seq(1, 4, 1)

class(neutral_snps)
detect_genomic_format(neutral_snps)

# i <- 1
invisible(pblapply(1:length(models), function(i){
  genomic_converter(data = neutral_snps, output = "vcf", filename = paste("ABC_model_", i, sep = ""), strata = sfiles[i], vcf.metadata = FALSE, vcf.stats = FALSE)
  # any(is.na(tmp$tidy.data$MARKERS))
  # any(is.na(tmp$tidy.data$POP_ID))
  # any(is.na(tmp$tidy.data$INDIVIDUALS))
  # any(is.na(tmp$tidy.data$GT))
  # any(is.na(tmp$tidy.data$REF))
  # any(is.na(tmp$tidy.data$ALT))
  # any(is.na(tmp$tidy.data$GT_VCF))
  # any(is.na(tmp$tidy.data$GT_BIN)) # This column has NAs....
  
  # Works just fine, underscores are automatically changed to dashes
  # read_strata(sfiles[i])
  
}))

# For every run I get an error that a separator is not valid, despite changing all "_" to "-" but the strata file is read in just fine and the package detects the genind class

# I also get an error about NAs created which I think is related to the NA in the POS field in the resulting VCF file, but everything else looks good:
# Warning messages:
# 1: Problem with `mutate()` input `LOCUS`.
# ℹ NAs introduced by coercion
# ℹ Input `LOCUS` is `stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_")`. 
# 2: In stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_") :
#   NAs introduced by coercion

# Looks like this just an error from reading in data with tifyr?
# Resulting VCF file looks different compared to Stacks VCF file, has just genotypes

```

I moved the resulting VCF files out of the ./radiator_genomic_converter* directories and into /media/owner/MYIOPSITTA/R/Origins_Selection/ABC/.

Followed instructions for calculating observed SFSs in this GitHub repo: https://github.com/isaacovercast/easySFS. I used Pycharm to use a virtual environment with Python3.


# Downsampling individuals for ABC

30 September 2020: Making the multidimensional SFS with all individuals per population in each model fails, probably due to the relatively large number of individuals used. Now trying downsampling of individuals per population to be used for ABC.

Read in the dataset of pre-processed neutral SNPs from the merged dataset. The number of individuals and loci is documented in BayeScan_post-processing.Rmd.
```{r echo = TRUE, eval = TRUE}

file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs.str"

neutral_snps <- read.structure(file.path(file.path(res_path, "merged"), file_nm), n.ind = 173, n.loc = 320, col.lab = 1, col.pop = 2, row.marknames = 1, onerowperind = FALSE, ask = FALSE, NA.char = "-9")
str(neutral_snps)

str(neutral_snps@tab)

```

Make a new data frame with metdata for these samples. Using DAPC output here. 
```{r echo = TRUE, eval = TRUE}

# Get sample locations from metadata in the same order of samples in the genind object
grp1 <- sapply(1:nrow(neutral_snps@tab), function(i){
  meta_dats$Site_Code[grep(paste("^", dimnames(neutral_snps@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(grp1)
length(grp1)

# Population identifiers by country, then sampling site
# Same order as in Structure file (taken from BayeScan_post-processing.Rmd)
all_sites <- c("CHAC", "ELGE", "EMBR", "SEMI-3", "SOLE", "1135", "1145", "BAGU", "BCAR", "PEIX", "ALGA", "BAIR", "LURO", "BAZO", "ERIO", "BARC", "MADR", "MALL", "SEVI", "ZARA", "GRCA", "FLOR", "ILLI", "WASH", "CNCT")

# Change levels to be in order of country and sampling sites above
grp1 <- factor(grp1, levels = all_sites)

# If all PCs used, then no points will show up, just labels for sampling sites
# Here selected the number of PCs that contained 60% of variation, and 2 discriminant functions
dapc1 <- dapc(neutral_snps, pop = grp1, n.da = 2, pca.select = "percVar", perc.pca = 60)

unique(meta_dats$Region)

all_regs <- c("Southwestern Uruguay", "South Central Uruguay", "Northern Argentina", "Southern Argentina", "Spain", "Southern U.S.", "Northern U.S.")

region <- meta_dats %>%
  filter(Sample_Name %in% dimnames(dapc1$ind.coord)[[1]]) %>%
  pull(Region)

dapc_df <- data.frame(
  X = dapc1$ind.coord[, 1],
  Y = dapc1$ind.coord[, 2]
  ) %>%
  dplyr::mutate(
    type = rep("Neutral merged SNPs", nrow(dapc1$ind.coord)),
    indiv = dimnames(dapc1$ind.coord)[[1]],
    region = gsub("United States", "U.S.", region),
    region = factor(region, levels = all_regs),
    site = grp1
  )

glimpse(dapc_df)

```

Make new files called "ABC_populations_modelX.txt" that contain strata or populations for each ABC model (necessary for writing out VCF file and getting observed SFS per ABC model).

Initialize all unique demes to be used across models: URY, NAR, SAR, SPA, USA, CNCT. 
```{r echo = TRUE, eval = TRUE}

# URY, 45 individuals
ury <- dapc_df %>%
  filter(grepl("Uruguay", region)) %>%
  pull(indiv) 

head(ury)
length(ury)
  
# NAR, 14 individuals
nar <- dapc_df %>%
  filter(grepl("Northern Argentina", region)) %>%
  pull(indiv) 

head(nar)
length(nar)  

# SAR, 18 individuals
sar <- dapc_df %>%
  filter(grepl("Southern Argentina", region)) %>%
  pull(indiv) 

head(sar)
length(sar)

# SPA, 28 individuals
spa <- dapc_df %>%
  filter(grepl("Spain", region)) %>%
  pull(indiv) 

head(spa)
length(spa)  

# USA (no CNCT), 41 individuals
usa <- dapc_df %>%
  filter(grepl("U.S.", region) & !grepl("CNCT", site)) %>%
  pull(indiv) 

head(usa)
length(usa)

# CNCT, 27 individuals
cnct <- dapc_df %>%
  filter(grepl("CNCT", site)) %>%
  pull(indiv) 

head(cnct)
length(cnct)

```

Read in the dataset of pre-processed neutral SNPs from the merged dataset as a .txt file, convert to data frame, subset by randomly sampled individuals per population, write out a new Structure file 
```{r echo = TRUE, eval = TRUE}

file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs.str"

struc <- read.table(file.path(file.path(res_path, "merged"), file_nm), skip = 1)
# glimpse(struc)
dim(struc) # 346 rows (173 individuals), 322 columns
head(struc[, 1]) # Sample names contained in the first column
head(struc[, 2]) # Population ID (single population) contained in second column
names(struc)

# Get the column headers

# Read the first line of metadata, these are the column names
col_nms <- readLines(file.path(file.path(res_path, "merged"), file_nm), n = 1)
col_nms

# Split out the column headers into a vector, one element per header
# No space that precedes the first locus column header
mrkrs <- strsplit(strsplit(col_nms, split = "\t")[[1]][3], split = "[[:space:]]")[[1]]
head(mrkrs)
length(mrkrs)

# Add the individual and population column headers that precede the locus column names
col_nms <- c("indiv", "pop", mrkrs)
head(col_nms)
length(col_nms)

# Add back the updated column names
# Convert the indiv column to character
# Looks good
names(struc) <- col_nms
struc$indiv <- as.character(struc$indiv)
glimpse(struc[, 1:10])

```

Filter this Structure file by randomly sampling individuals per population to be used in ABC. Randomly sample 12 individuals each for URY, NAR, SAR, SPA, USA, CNCT, or take all indivs if less present. In model 1, the randomly sampled URY and NAR individuals will be combined into URY-NAR.
```{r echo = TRUE, eval = TRUE}

n <- 12

# For URY, randomly sample from two sites near exporter's aviaries in southcentral URY, and 2 sites in west 
set.seed(seed)
ury_r <- dapc_df %>%
  filter(grepl("Uruguay", region)) %>%
  filter(site %in% c("BCAR", "PEIX", "ELGE", "EMBR")) %>%
  pull(indiv) %>%
  sample(n, replace = FALSE)
ury_r

# Randomly sample 12 of 14 NAR
nar_r <- sample(nar, n, replace = FALSE)

# For Spain, randomly sample 12 birds across all 6 sites  
set.seed(seed)
spa_r <- dapc_df %>%
  filter(grepl("Spain", region)) %>%
  pull(indiv) %>%
  sample(n, replace = FALSE) 
spa_r

# For CNCT, randomly sample 12 birds
set.seed(seed)
cnct_r <- sample(cnct, n, replace = FALSE)
cnct_r

# For the U.S., use all 4 WASH, then randomly sample 4 from ILLI and 4 from FLOR
set.seed(seed)
usa_r <- dapc_df %>%
      filter(grepl("U.S.", region)) %>%
      filter(site == "WASH") %>%
      pull(indiv) %>%
  c(
    dapc_df %>%
      filter(grepl("U.S.", region)) %>%
      filter(site == "ILLI") %>%
      pull(indiv) %>%
      sample(4, replace = FALSE)
  ) %>%
  c(
    dapc_df %>%
      filter(grepl("U.S.", region)) %>%
      filter(site == "FLOR") %>%
      pull(indiv) %>%
      sample(4, replace = FALSE)
  )

usa_r

# 18 SAR individuals, randomly sample 12
set.seed(seed)
sar_r <- sample(sar, n, replace = FALSE)
sar_r

```

Subset the data frame by these individuals and write out a new Structure file to the ABC folder. Note that population IDs are the same as those used for Structure (sampling sites), but these will be updated in files made for ABC. 12 individuals per ABC population (not counting URY-NAR), 72 individuals total.
```{r echo = TRUE, eval = TRUE}

# 12 URY, 12 NAR, 12 SPA, 12 CNCT, 12 USA, 12 SAR
neutral_ds <- struc[grep(paste(paste("^", c(ury_r, nar_r, spa_r, cnct_r, usa_r, sar_r), "$", sep = ""), collapse = "|"), struc$indiv), ]
dim(neutral_ds) # 144 rows = 72 individuals, 320 SNPs
ncol(neutral_ds) - 2

file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs_rsampIndivs.str"
file.remove(file.path(out_path, file_nm))

header <- c("\t","\t", paste(paste(names(neutral_ds)[-grep("^indiv$|^pop$", names(neutral_ds))]), collapse = " "), "\n", sep = "")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(neutral_ds), function(i){
  
  cat(c(neutral_ds$indiv[i], "\t", neutral_ds$pop[i], "\t", paste(paste(neutral_ds[i, -grep("^indiv$|^pop$", names(neutral_ds))], collapse = " "), "\n", sep = "")), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened the file in Vim to doublecheck structure, looks good
# Use :set list in Vim to see invisible characters (tabs)

```

Read in the downsampled dataset and run DAPC as a visual check, also to get metadata.
```{r echo = TRUE, eval = TRUE}

file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs_rsampIndivs.str"

neutral_snps_ds <- read.structure(file.path(out_path, file_nm), n.ind = 94, n.loc = 320, col.lab = 1, col.pop = 2, row.marknames = 1, onerowperind = FALSE, ask = FALSE, NA.char = "-9")
str(neutral_snps_ds)

str(neutral_snps_ds@tab)

```

Make a new data frame with metdata for these samples. Using DAPC output here. 
```{r echo = TRUE, eval = TRUE}

# Get sample locations from metadata in the same order of samples in the genind object
grp1 <- sapply(1:nrow(neutral_snps_ds@tab), function(i){
  meta_dats$Site_Code[grep(paste("^", dimnames(neutral_snps_ds@tab)[[1]][i], "$", sep = ""), meta_dats$Sample_Name)]
})
head(grp1)
length(grp1)
unique(grp1)

# CONTINUE, update colors, shapes

# Population identifiers by country, then sampling site
all_sites <- c("ELGE", "EMBR", "BCAR", "PEIX", "ALGA", "BAIR", "LURO", "BAZO", "ERIO", "BARC", "MADR", "ZARA", "GRCA", "MALL", "FLOR", "ILLI", "WASH", "CNCT")
length(all_sites)

# Change levels to be in order of country and sampling sites above
grp1 <- factor(grp1, levels = all_sites)

# If all PCs used, then no points will show up, just labels for sampling sites
# Here selected the number of PCs that contained 60% of variation, and 2 discriminant functions
dapc1 <- dapc(neutral_snps_ds, pop = grp1, n.da = 2, pca.select = "percVar", perc.pca = 30)

unique(meta_dats$Region)

all_regs <- c("Southwestern Uruguay", "South Central Uruguay", "Northern Argentina", "Southern Argentina", "Spain", "Southern U.S.", "Northern U.S.")

region <- meta_dats %>%
  filter(Sample_Name %in% dimnames(dapc1$ind.coord)[[1]]) %>%
  pull(Region)

dapc_df <- data.frame(
  X = dapc1$ind.coord[, 1],
  Y = dapc1$ind.coord[, 2]
  ) %>%
  dplyr::mutate(
    type = rep("Neutral merged SNPs", nrow(dapc1$ind.coord)),
    indiv = dimnames(dapc1$ind.coord)[[1]],
    region = gsub("United States", "U.S.", region),
    region = factor(region, levels = all_regs),
    site = grp1
  )

glimpse(dapc_df)
# View(dapc_df)

# Make colors by country, hues by sampling location
levels(grp1)

# Uruguay in blues, Argentina in grays, Spain in reds, US in golds
cols <- c("navy", "royalblue", "turquoise", "cornflowerblue", "black", "gray5", "gray25", "gray50", "gray75", "firebrick", "maroon", "brown", "coral", "orangered", "orange", "gold2", "yellow2", "gold4")
length(cols)

# Shapes by country
pchs <- c(rep(19, 4), rep(18, 5), rep(15, 5), rep(17, 4))
length(pchs)

dapc_df %>%
  ggplot(aes(x = X, y = Y, color = site, shape = site)) +
  geom_hline(aes(yintercept = 0), linetype = "solid", color = "black", size = 0.25) +
  geom_vline(aes(xintercept = 0), linetype = "solid", color = "black", size = 0.25) +
  geom_point(size = 6) +
  facet_wrap(~ type) +
  scale_shape_manual(values = pchs) +
  scale_color_manual(values = alpha(cols, 0.75)) +
  xlab("Dimension 1") +
  ylab("Dimension 2") +
  theme_bw()

# Patterns look similar to the full dataset of 173 individuals, except CNCT overlaps with all others and GRCA falls out as different when using perc.pca of 60. When using perc.pca of 30, patterns look more similar to full dataset of 173 individuals with perc.pca of 60

```

# Files for ABC with downsampled individuals

Model 1: 5 demes. Make a tab delimited file with column headers INDIVIDUALS and STRATA for radiator::genomic_converter. Make a tab delimited file without headers for the easy_SFS.py script.
```{r echo = TRUE, eval = FALSE}

ury_nar <- c(ury_r, nar_r)

# Make a temporary data frame for Model 1
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury_nar, spa_r, cnct_r, usa_r, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY-NAR",
      `South Central Uruguay` = "URY-NAR",
      `Northern Argentina` = "URY-NAR",
      `Spain` = "SPA",
      `Northern U.S.` = "USA",
      `Southern U.S.` = "USA",
      `Southern Argentina` = "SAR"
    ),
    region = ifelse(site == "CNCT", "CNCT", region)
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY-NAR` = "pop1",
      `SPA` = "pop2",
      `CNCT` = "pop3",
      `USA` = "pop4",
      `SAR` = "pop5"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df) 

# Text file for radiator
file_nm <- "radiator_strata_model_1.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_model_1.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both file in Vim, both look good

```

Models 2-4: 6 demes.
```{r echo = TRUE, eval = FALSE}

ury_nar <- c(ury_r, nar_r)

# Make a temporary data frame for Model 2
tmp_df <- dapc_df %>%
  filter(indiv %in% c(ury_nar, spa_r, cnct_r, usa_r, sar)) %>%
  droplevels() %>%
  dplyr::mutate(
    region = as.character(region),
    region = recode(
      region,
      `Southwestern Uruguay` = "URY",
      `South Central Uruguay` = "URY",
      `Northern Argentina` = "NAR",
      `Spain` = "SPA",
      `Northern U.S.` = "USA",
      `Southern U.S.` = "USA",
      `Southern Argentina` = "SAR"
    ),
    region = ifelse(site == "CNCT", "CNCT", region)
  ) %>%
  dplyr::mutate(
    pop = region,
    pop = recode(
      pop,
      `URY` = "pop1",
      `SPA` = "pop2",
      `CNCT` = "pop3",
      `USA` = "pop4",
      `NAR` = "pop5",
      `SAR` = "pop6"
    )
  )
glimpse(tmp_df)  
# View(tmp_df) # looks good

# Order by population
tmp_df <- tmp_df %>%
  arrange(-desc(pop))

glimpse(tmp_df)

# Text file for radiator
file_nm <- "radiator_strata_models_2to4.tsv"
file.remove(file.path(out_path, file_nm))

header <- c(paste(c("INDIVIDUALS", "STRATA"), collapse = "\t"), "\n")

cat(header, file = file.path(out_path, file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))


# Text file for easy_SFS.py (no column headers)
file_nm <- "easySFS_popfile_models_2to4.txt"
file.remove(file.path(out_path, file_nm))

invisible(pbsapply(1:nrow(tmp_df), function(i){
  
  # Substituted "_" for "-" as this was done in radiator for sample names when convertin to VCF
  cat(c(gsub("_", "-", tmp_df$indiv[i]), "\t", tmp_df$pop[i], "\n"), file = file.path(out_path, file_nm), append = TRUE, sep = "")
  
}))

# Opened both file in Vim, both look good

```

Note that populations are the same for models 3 and 4, so I didn't make separate files for these.

Use radiator to convert from genind format to VCF per model, write out VCF files per model. VCF files are the same for models 2 - 4. radiator path setting is bad: assumes a path inside thre current working directory, so I have to set my directory for it to work
```{r echo = TRUE, eval = FALSE}

setwd(out_path)

sfiles <- list.files(out_path, pattern = "^radiator_", full.names = TRUE)
sfiles

models <- seq(1, 2, 1)
suffs <- c("1", "2to4")

str(neutral_snps_ds)
class(neutral_snps_ds)
detect_genomic_format(neutral_snps_ds)

# i <- 1
invisible(pblapply(1:length(models), function(i){
  genomic_converter(data = neutral_snps_ds, output = "vcf", filename = paste("ABC_model_", suffs[i], sep = ""), strata = sfiles[i], vcf.metadata = FALSE, vcf.stats = FALSE)
  # any(is.na(tmp$tidy.data$MARKERS))
  # any(is.na(tmp$tidy.data$POP_ID))
  # any(is.na(tmp$tidy.data$INDIVIDUALS))
  # any(is.na(tmp$tidy.data$GT))
  # any(is.na(tmp$tidy.data$REF))
  # any(is.na(tmp$tidy.data$ALT))
  # any(is.na(tmp$tidy.data$GT_VCF))
  # any(is.na(tmp$tidy.data$GT_BIN)) # This column has NAs....
  
  # Works just fine, underscores are automatically changed to dashes
  # read_strata(sfiles[i])
  
}))

# For every run I get an error that a separator is not valid, despite changing all "_" to "-" but the strata file is read in just fine and the package detects the genind class

# I also get an error about NAs created which I think is related to the NA in the POS field in the resulting VCF file, but everything else looks good:
# Warning messages:
# 1: Problem with `mutate()` input `LOCUS`.
# ℹ NAs introduced by coercion
# ℹ Input `LOCUS` is `stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_")`. 
# 2: In stringi::stri_join(LOCUS, as.numeric(POS) - 1, sep = "_") :
#   NAs introduced by coercion

# Looks like this just an error from reading in data with tifyr?
# Resulting VCF file looks different compared to Stacks VCF file, has just genotypes

```

I moved the resulting VCF files out of the ./radiator_genomic_converter* directories and into /media/owner/MYIOPSITTA/R/Origins_Selection/ABC/.

Followed instructions for calculating observed SFSs in this GitHub repo: https://github.com/isaacovercast/easySFS. I used Pycharm to use a virtual environment with Python3.