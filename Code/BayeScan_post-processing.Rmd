---
title: "BayeScan post-processing"
author: "Grace Smith-Vidaurre"
date: "September 21, 2020"
output: html_document
---

```{r setup, eval = TRUE, echo = FALSE}

knitr::opts_knit$set(root.dir = "/home/owner/Desktop/GitHub_repos/origins-selection")

```

Purpose: Read in BayeScan results and get outlier loci. These will be used to split off the neutral loci that will be used in demogrpahic analyses, and the outlier loci hemselves will be taken through an outlier analysis pipeline.

```{r echo = TRUE, eval = TRUE, message = FALSE}

rm(list = ls())

X <- c("tidyverse", "pbapply", "data.table", "adegenet", "openxlsx")
invisible(lapply(X, library, character.only = TRUE))

# Path to the metadata spreadsheet that will be updated
xls_path <- "/home/owner/Desktop/MANUSCRIPTS/Origins_Selection/DATA/Metadata_Barcodes"

# Path to Stacks output, including the HWE filtered SNPs in Structure format 
res_path <- "/media/owner/MYIOPSITTA/R/Origins_Selection/stacks"

# Path where BayeScan files will be written
out_path <- "/media/owner/MYIOPSITTA/R/Origins_Selection/BayeScan_mergedSNPs"

gpath <- "/home/owner/Desktop/MANUSCRIPTS/Origins_Selection/GRAPHICS"

seed <- 401

# Source the BayeScan R function
# I copied this into my external hard drive from BayeScan2.1/R functions/
source(file.path(out_path, "plot_R.r"))

```

Read in metadata.
```{r echo = TRUE, eval = TRUE}

meta_dats <- read.xlsx(file.path(xls_path, "Mymon_RADlibraries_2015_2019_CombinedMetadata.xlsx"))
glimpse(meta_dats)

```

# Read in BayeScan results

Search for outliers using 2 false discovery rates (FDRs): q-value of 0.2 and q-value of 0.05.
```{r echo = TRUE, eval = TRUE}

# From the documentation inside plot_R.r:

# Arguments:
# - file is the name of your file ex: "output_fst.txt"
# - the q-value threshold corresponding to the target False Discovery Rate (FDR)
# - size is the size of the points and text labels for outliers
# - pos is the distance between the points and the labels 
# - highlight is a optional list of marker indices to display in red.
# - name_highlighted alows to write the indices of highlighted markers instead of using a point like the other markers
# - add_text adds the indices of the outlier markers

# Plotting outliers
res_01 <- plot_bayescan(res = file.path(out_path, "BS_01_AllInvasiveVersusNative_fst.txt"), FDR = 0.20)
res_01

# Iterate over files and q-values to find the outliers
res_files <- list.files(path = out_path, pattern = "_fst.txt$")
qvals <- c(0.2, 0.05)

# 64 comparisons, including 5 randomizations
length(res_files)

outliers_df <- rbindlist(pblapply(1:length(res_files), function(i){
  
  tmp_df2 <- rbindlist(pblapply(1:length(qvals), function(q){
    
    comparison <- gsub("_fst.txt", "", res_files[i])
    
    tmp <- plot_bayescan(res = file.path(out_path, res_files[i]), FDR = qvals[q])
  
    # Numeric indices of loci, in the same order as the original Structure file
    ols <- tmp$outliers
    
    if(length(ols) > 0){
      tmp_df <- data.frame(
        comparison = comparison,
        q_value = qvals[q],
        outlier_indices = ols
      )
    } else {
      tmp_df <- data.frame(
        comparison = comparison,
        q_value = qvals[q],
        outlier_indices = NA
      )
    }

    return(tmp_df)
    
  }))
  
  return(tmp_df2)
  
}))

outliers_df

```

# Outlier validation

How many outliers were identified in each of the random population contrasts? No outliers were identified in any of the 5 random contrasts that I created for validation. Nice!
```{r echo = TRUE, eval = TRUE}

outliers_df %>%
  filter(grepl("Random", comparison))

```

# Outliers across population contrasts

How many population contrasts had outliers? Which had the most outliers?
```{r echo = TRUE, eval = TRUE}

# Number of comparisons with outliers at q-value of 0.2
# 33 out of the 61 non-random contrasts
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  filter(q_value == 0.2) %>%
  pull(comparison) %>%
  unique() %>%
  length()

# Number of comparisons with outliers at q-value of 0.05
# 29 out of the 61 non-random contrasts
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  filter(q_value == 0.05) %>%
  pull(comparison) %>%
  unique() %>%
  length()

# Total outliers at q-value of 0.2
# 241 outliers
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  filter(q_value == 0.2) %>%
  pull(outlier_indices) %>%
  unique() %>%
  length()


# Total outliers at q-value of 0.05
# 155 outliers
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  filter(q_value == 0.05) %>%
  pull(outlier_indices) %>%
  unique() %>%
  length()


# Which comparisons had the most outliers and how many? at q-value of 0.2
# 89 outliers, BS_15-7_ILLI_VersusAllNative
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  group_by(comparison) %>%
  filter(q_value == 0.2) %>%
  dplyr::summarise(
    n_outliers = length(outlier_indices)
  ) %>%
  dplyr::summarise(
    max_n = max(n_outliers)
  ) %>%
  inner_join(
    outliers_df %>%
      filter(!grepl("Random", comparison)) %>%
      filter(!is.na(outlier_indices)) %>%
      group_by(comparison) %>%
      filter(q_value == 0.2) %>%
      dplyr::summarise(
        n_outliers = length(outlier_indices)
    ),
    by = c("max_n" = "n_outliers")
  )
  

# Which comparisons had the most outliers and how many? at q-value of 0.05
# 63 outliers, BS_15-4_MALL_VersusAllNative
outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  group_by(comparison) %>%
  filter(q_value == 0.05) %>%
  dplyr::summarise(
    n_outliers = length(outlier_indices)
  ) %>%
  dplyr::summarise(
    max_n = max(n_outliers)
  ) %>%
  inner_join(
    outliers_df %>%
      filter(!grepl("Random", comparison)) %>%
      filter(!is.na(outlier_indices)) %>%
      group_by(comparison) %>%
      filter(q_value == 0.05) %>%
      dplyr::summarise(
        n_outliers = length(outlier_indices)
    ),
    by = c("max_n" = "n_outliers")
  )

```

Checking out the number of outliers across comparisons at q-value of 0.2.
```{r echo = TRUE, eval = TRUE}

outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  group_by(comparison) %>%
  filter(q_value == 0.05) %>%
  dplyr::summarise(
    n_outliers = length(outlier_indices)
  ) %>%
  arrange(desc(n_outliers)) %>%
  View()


```

# Unique outlier loci

Get the indices of unique outlier loci across comparisons and q-values. 241 unique outliers.
```{r echo = TRUE, eval = TRUE}

unique_outliers <- outliers_df %>%
  filter(!grepl("Random", comparison)) %>%
  filter(!is.na(outlier_indices)) %>%
  pull(outlier_indices) %>%
  unique()

length(unique_outliers)

```

# Split loci into outlier and neutral datasets

Read in the HWE and missing data filtered merged SNPs with duplicated positive controls dropped.
```{r echo = TRUE, eval = TRUE}

struc <- read.table(file.path(file.path(res_path, "merged"), "merged_HWE_missingData_filters_noPosControlDups.str"), skip = 1)
# glimpse(struc)
dim(struc) # 346 rows (173 individuals), 563 columns
head(struc[, 1]) # Sample names contained in the first column
head(struc[, 2]) # Population ID (single population) contained in second column
names(struc)

# Get the column headers

# Read the first line of metadata, these are the column names
col_nms <- readLines(file.path(file.path(res_path, "merged"), "merged_HWE_missingData_filters_noPosControlDups.str"), n = 1)
col_nms

# Split out the column headers into a vector, one element per header
mrkrs <- strsplit(strsplit(col_nms, split = "\t")[[1]][3], split = "[[:space:]]")[[1]]
head(mrkrs)
length(mrkrs)

# Get rid of the space that precedes the first locus column header
mrkrs <- mrkrs[-which(mrkrs == "")]
head(mrkrs)
length(mrkrs)

# Add the individual and population column headers that precede the locus column names
col_nms <- c("indiv", "pop", mrkrs)
head(col_nms)
length(col_nms)

# Add back the updated column names
# Convert the indiv column to character
# Looks good
names(struc) <- col_nms
struc$indiv <- as.character(struc$indiv)
glimpse(struc[, 1:10])

```

Filter this Structure file to remove outliers and retain neutral loci.
```{r echo = TRUE, eval = TRUE}

# Get locus IDs from the outlier indices
length(mrkrs)
outlier_ids <- mrkrs[unique_outliers]

neutral_SNPs <- struc[, -grep(paste(paste("^", outlier_ids, "$", sep = ""), collapse = "|"), names(struc))]
dim(neutral_SNPs) # 173 individuals, 320 SNPs
ncol(neutral_SNPs) - 2

outlier_SNPs <- struc[, grep(paste(paste("^", c("indiv", "pop", outlier_ids), "$", sep = ""), collapse = "|"), names(struc))]
dim(outlier_SNPs) # 173 individuals, 241 SNPs
ncol(outlier_SNPs) - 2

# All SNPs accounted for
length(c(names(neutral_SNPs)[-grep("indiv|pop", names(neutral_SNPs))],
  names(outlier_SNPs)[-grep("indiv|pop", names(outlier_SNPs))]))

```

Make sure to update the population identifiers to be integers for sampling sites, in the order in which plotting will be done in distruct. This information won't be used by Structure, given how I'm parameterizing the runs. Finally, changed -9999 for missing data to -9.
```{r echo = TRUE, eval = TRUE}

# Population identifiers by country, then sampling site
all_sites <- c("CHAC", "ELGE", "EMBR", "SEMI-3", "SOLE", "1135", "1145", "BAGU", "BCAR", "PEIX", "ALGA", "BAIR", "LURO", "BAZO", "ERIO", "BARC", "MADR", "MALL", "SEVI", "ZARA", "GRCA", "FLOR", "ILLI", "WASH", "CNCT")

# Update population identifiers
indivs <- neutral_SNPs$indiv

# i <- 1
sites <- sapply(1:length(indivs), function(i){
  meta_dats %>%
    filter(Sample_Name == indivs[i]) %>%
    pull(Site_Code) %>%
    as.character()
})

# Make integers in the order of all sites above, and in order by diploid individuals 
neutral_SNPs$pop <- as.numeric(factor(sites, levels = all_sites))
outlier_SNPs$pop <- as.numeric(factor(sites, levels = all_sites))

# Change missing data value
neutral_SNPs[neutral_SNPs == -9999] <- -9
outlier_SNPs[outlier_SNPs == -9999] <- -9

glimpse(neutral_SNPs)
glimpse(outlier_SNPs)

```

Wrote the neutral SNPs out as a new file in Structure format. Make sure to set sep = "" in cat() to avoid extra spaces.
```{r echo = TRUE, eval = TRUE}

# Write a new file for the neutral SNPs
file_nm <- "merged_HWE_missingData_filters_noPosControlDups_neutralSNPs.str"
file.remove(file.path(file.path(res_path, "merged"), file_nm))

header <- c("\t","\t", paste(paste(names(neutral_SNPs)[-grep("^indiv$|^pop$", names(neutral_SNPs))]), collapse = " "), "\n", sep = "")

cat(header, file = file.path(file.path(res_path, "merged"), file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(neutral_SNPs), function(i){
  
  cat(c(neutral_SNPs$indiv[i], "\t", neutral_SNPs$pop[i], "\t", paste(paste(neutral_SNPs[i, -grep("^indiv$|^pop$", names(neutral_SNPs))], collapse = " "), "\n", sep = "")), file = file.path(file.path(res_path, "merged"), file_nm), append = TRUE, sep = "")
  
}))

# Opened the file in Vim to doublecheck structure, looks good
# Use :set list in Vim to see invisible characters (tabs)

```

Wrote the outlier SNPs out as a new file in Structure format.
```{r echo = TRUE, eval = TRUE}

# Write a new file for the outlier SNPs
file_nm <- "merged_HWE_missingData_filters_noPosControlDups_outlierSNPs.str"
file.remove(file.path(file.path(res_path, "merged"), file_nm))

header <- c("\t","\t", paste(paste(names(outlier_SNPs)[-grep("^indiv$|^pop$", names(outlier_SNPs))]), collapse = " "), "\n", sep = "")

cat(header, file = file.path(file.path(res_path, "merged"), file_nm), append = TRUE, sep = "")

invisible(pbsapply(1:nrow(outlier_SNPs), function(i){
  
  cat(c(outlier_SNPs$indiv[i], "\t", outlier_SNPs$pop[i], "\t", paste(paste(outlier_SNPs[i, -grep("^indiv$|^pop$", names(outlier_SNPs))], collapse = " "), "\n", sep = "")), file = file.path(file.path(res_path, "merged"), file_nm), append = TRUE, sep = "")
  
}))

# Opened the file in Vim to doublecheck structure, looks good
# Use :set list in Vim to see invisible characters (tabs)

```
